{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2aca8168-62ec-4bba-93f0-73da08cd1920",
   "metadata": {
    "id": "2aca8168-62ec-4bba-93f0-73da08cd1920"
   },
   "source": [
    "---\n",
    "Тема: Суммаризация и краткий перессказ\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13f702",
   "metadata": {
    "id": "cf13f702"
   },
   "source": [
    "## Сценарий\n",
    "\n",
    "Предположим, у вас есть набор документов (PDF-файлы, концептуальные страницы, вопросы клиентов и т.д.), и вы хотите обобщить содержание.\n",
    "\n",
    "LLM - отличный инструмент для этого, учитывая их умение понимать и синтезировать текст.\n",
    "\n",
    "В этом пошаговом руководстве мы рассмотрим, как выполнить обобщение документов с помощью LLM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e233997",
   "metadata": {
    "id": "8e233997"
   },
   "source": [
    "![Image description](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/summarization_use_case_1.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715b4ff",
   "metadata": {
    "id": "4715b4ff",
    "tags": []
   },
   "source": [
    "## Обзор\n",
    "\n",
    "Центральным вопросом при создании модуля краткого перессказа является то, как передать ваши документы в контекстное окно LLM. Двумя распространенными подходами для этого являются:\n",
    "\n",
    "1. `Stuff`: Просто \"запихните\" все ваши документы в один промпт. Это самый простой подход (вот [здесь](https://python.langchain.com/docs/modules/chains#lcel-chains) дополнительная информация по `create_stuff_documents_chain` конструктору, который используется для этого метода).\n",
    "\n",
    "2. `Map-reduce`: Обобщите каждый документ отдельно на шаге \"map\" и затем преобразуйте в итоговое резюме на шаге \"reduce\" (вот [здесь](https://python.langchain.com/docs/modules/chains#legacy-chains) можно найти дополнительную информацию по `MapReduceDocumentsChain`, который используется в этом методе)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ec66bc",
   "metadata": {
    "id": "08ec66bc"
   },
   "source": [
    "![Image description](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/summarization_use_case_2.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea785ac",
   "metadata": {
    "id": "bea785ac"
   },
   "source": [
    "## Быстрый старт\n",
    "\n",
    "Для краткости отметим, что любой конвейер может быть обернут в один объект: `load_summarize_chain`.\n",
    "\n",
    "Предположим, мы хотим подвести итог записи в блоге. Мы можем сделать это с помощью нескольких строк кода.\n",
    "\n",
    "Сначала задаем переменные окружения и устанавливаем пакеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578d6a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T15:28:31.465044Z",
     "iopub.status.busy": "2024-06-14T15:28:31.464272Z",
     "iopub.status.idle": "2024-06-14T15:28:35.441290Z",
     "shell.execute_reply": "2024-06-14T15:28:35.440454Z",
     "shell.execute_reply.started": "2024-06-14T15:28:31.465001Z"
    },
    "id": "578d6a90",
    "outputId": "51bb4525-e80b-4ba6-a750-2081965a28c2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  yandexcloud==0.255.0 chromadb==0.5.0 langchain==0.1.4 requests==2.31.0 bs4==0.0.2 langchainhub==0.1.18 transformers==4.41.2\n",
    "\n",
    "# Определите переменные SA_ID, KEY_ID, YC_FOLDER_ID или загрузите их из .env файла\n",
    "# import dotenv\n",
    "\n",
    "# dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36138740",
   "metadata": {
    "id": "36138740"
   },
   "source": [
    "Можно использовать `chain_type=\"stuff\"\n",
    "\n",
    "А также `chain_type=\"map_reduce\"` или `chain_type=\"refine\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b1ec58-5f46-402a-bd71-91bfe57eb20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T13:34:49.193825Z",
     "iopub.status.busy": "2024-03-14T13:34:49.193031Z",
     "iopub.status.idle": "2024-03-14T13:34:49.204094Z",
     "shell.execute_reply": "2024-03-14T13:34:49.203446Z",
     "shell.execute_reply.started": "2024-03-14T13:34:49.193782Z"
    }
   },
   "source": [
    "##### Получаем IAM-токен для работы с YandexGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6760c68f-9172-4281-abf5-6dc8ba74ac2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T15:28:35.443701Z",
     "iopub.status.busy": "2024-06-14T15:28:35.442769Z",
     "iopub.status.idle": "2024-06-14T15:28:35.936954Z",
     "shell.execute_reply": "2024-06-14T15:28:35.935217Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.443665Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SA_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1968/3200162863.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mservice_account_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SA_ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mkey_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"KEY_ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfolder_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"YC_FOLDER_ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SA_ID'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import jwt\n",
    "import requests\n",
    "import os\n",
    "service_account_id = os.environ[\"SA_ID\"]\n",
    "key_id = os.environ[\"KEY_ID\"]\n",
    "folder_id = os.environ[\"YC_FOLDER_ID\"]\n",
    "private_key = \"-----BEGIN PRIVATE KEY-----ЗДЕСЬ УКАЖИТЕ ВАШ ПРИВАТНЫЙ КЛЮЧ-----END PRIVATE KEY-----\\n\"\n",
    "# Получаем IAM-токен\n",
    "now = int(time.time())\n",
    "payload = {\n",
    "        'aud': 'https://iam.api.cloud.yandex.net/iam/v1/tokens',\n",
    "        'iss': service_account_id,\n",
    "        'iat': now,\n",
    "        'exp': now + 360}\n",
    "# Формирование JWT\n",
    "encoded_token = jwt.encode(\n",
    "    payload,\n",
    "    private_key,\n",
    "    algorithm='PS256',\n",
    "    headers={'kid': key_id})\n",
    "url = 'https://iam.api.cloud.yandex.net/iam/v1/tokens'\n",
    "x = requests.post(url,  \n",
    "                  headers={'Content-Type': 'application/json'},\n",
    "                  json = {'jwt': encoded_token}).json()\n",
    "token = x['iamToken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd271681",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.937756Z",
     "iopub.status.idle": "2024-06-14T15:28:35.938200Z",
     "shell.execute_reply": "2024-06-14T15:28:35.938018Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.937997Z"
    },
    "id": "fd271681",
    "outputId": "bcd44875-2454-4b65-b61d-80a1428ca86d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.chat_models import ChatYandexGPT\n",
    "# url = \"https://cloud.yandex.ru/ru/docs/yandexgpt/concepts/\"\n",
    "url = \"https://cloud.yandex.ru/ru/docs/security/standarts\"\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt-lite/latest\"\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt/latest\"\n",
    "model_uri = \"gpt://\"+str(folder_id)+\"/summarization/latest\" #модель, специально обученная для решения задачи краткого перессказа\n",
    "llm = ChatYandexGPT(iam_token = token, model_uri=model_uri, temperature = 0)\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "print(chain.run(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b36e1",
   "metadata": {
    "id": "615b36e1"
   },
   "source": [
    "## Вариант 1. Stuff\n",
    "\n",
    "Когда мы используем `load_summarize_chain` с `chain_type=\"stuff\"`, мы применяем [StuffDocumentsChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.StuffDocumentsChain.html#langchain.chains.combine_documents.stuff.StuffDocumentsChain).\n",
    "\n",
    "Цепочка возьмет список документов, вставит их все в приглашение и передаст это приглашение LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45585d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.942218Z",
     "iopub.status.idle": "2024-06-14T15:28:35.942787Z",
     "shell.execute_reply": "2024-06-14T15:28:35.942598Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.942576Z"
    },
    "id": "ef45585d",
    "outputId": "8f6b5419-7c82-4b1d-ca26-a8c0f5b0e0e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Определим промпт\n",
    "prompt_template = \"\"\"Напишите краткое изложение следующего:\n",
    "\"{text}\"\n",
    "Краткое изложение:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Определим LLM цепочку\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt-lite/latest\"\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt/latest\"\n",
    "model_uri = \"gpt://\"+str(folder_id)+\"/summarization/latest\" #модель, специально обученная для решения задачи краткого перессказа\n",
    "llm = ChatYandexGPT(iam_token = token, model_uri=model_uri, temperature = 0)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Определим StuffDocumentsChain\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
    "\n",
    "docs = loader.load()\n",
    "print(stuff_chain.run(docs))\n",
    "# print(stuff_chain.invoke(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4e4a43",
   "metadata": {
    "id": "4e4e4a43"
   },
   "source": [
    "Мы можем видеть, что мы воспроизводим более ранний результат, используя `load_summarize_chain`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6cabee",
   "metadata": {
    "id": "ad6cabee"
   },
   "source": [
    "## Вариант 2. Map-Reduce\n",
    "\n",
    "Давайте разберемся с подходом map reduce. Для этого мы сначала сопоставим каждый документ с отдельным перессказом, используя `LLMChain`. После этого используем `ReduceDocumentsChain` чтоб объединить эти пересказы в общую краткую сводку.\n",
    "\n",
    "Сначала мы указываем цепочку LLMChain, которую будем использовать для сопоставления каждого документа с отдельным кратким пересказом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6773c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.943670Z",
     "iopub.status.idle": "2024-06-14T15:28:35.944318Z",
     "shell.execute_reply": "2024-06-14T15:28:35.944165Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.944147Z"
    },
    "id": "a1e6773c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt-lite/latest\"\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt/latest\"\n",
    "model_uri = \"gpt://\"+str(folder_id)+\"/summarization/latest\" #модель, специально обученная для решения задачи краткого перессказа\n",
    "llm = ChatYandexGPT(iam_token = token, model_uri=model_uri, temperature = 0)\n",
    "\n",
    "# Map\n",
    "map_template = \"\"\"Ниже приведен набор документов\n",
    "{docs}\n",
    "Основываясь на этом списке документов, пожалуйста, определи основные темы\n",
    "Полезный ответ:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ce8ce-919d-4ded-bbd5-a53a8a30bc66",
   "metadata": {
    "id": "272ce8ce-919d-4ded-bbd5-a53a8a30bc66"
   },
   "source": [
    "Можем также использовать Prompt Hub для хранения и извлечения промптов.\n",
    "\n",
    "Это будет работать с вашим [LangSmith API key](https://docs.smith.langchain.com/).\n",
    "\n",
    "Например, пример map промпта [здесь](https://smith.langchain.com/hub/rlm/map-prompt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce48b805-d98b-4e0f-8b9e-3b3e72cad3d3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.945028Z",
     "iopub.status.idle": "2024-06-14T15:28:35.945615Z",
     "shell.execute_reply": "2024-06-14T15:28:35.945474Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.945454Z"
    },
    "id": "ce48b805-d98b-4e0f-8b9e-3b3e72cad3d3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "map_prompt = hub.pull(\"rlm/map-prompt\")\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3c331",
   "metadata": {
    "id": "bee3c331"
   },
   "source": [
    "`ReduceDocumentsChain` обрабатывает получение результатов сопоставления документов и сведение их в единый вывод. Он оборачивает общий `CombineDocumentsChain` (как и `StuffDocumentsChain`) но добавляет возможность сворачивать документы перед передачей их в `CombineDocumentsChain` если их совокупный размер превышает `token_max`. В этом примере мы действительно можем сократить цепочку для объединения всех документов, чтобы также свернуть наши документы.\n",
    "\n",
    "Таким образом, если совокупное количество токенов в наших сопоставленных документах превысит 4000 токенов, то мы будем рекурсивно передавать документы пакетами по < 4000 токенов в наш`StuffDocumentsChain` для создания групповых сводок.И как только эти групповые сводки в совокупности составят менее 4000 токенов, мы передадим их все в последний раз в `StuffDocumentsChain` чтобы создать итоговую сводку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a718890-99ab-439a-8f79-b9ae9c58ad24",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.946323Z",
     "iopub.status.idle": "2024-06-14T15:28:35.946861Z",
     "shell.execute_reply": "2024-06-14T15:28:35.946744Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.946726Z"
    },
    "id": "6a718890-99ab-439a-8f79-b9ae9c58ad24",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reduce\n",
    "reduce_template = \"\"\"Ниже приведен набор кратких выжимок из документов:\n",
    "{docs}\n",
    "Возьми их и сформируй из них окончательное, сводное резюме по основным темам.\n",
    "Полезный ответ:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189184a-673e-4530-8a6b-57b091045d87",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.947791Z",
     "iopub.status.idle": "2024-06-14T15:28:35.948106Z",
     "shell.execute_reply": "2024-06-14T15:28:35.947958Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.947943Z"
    },
    "id": "f189184a-673e-4530-8a6b-57b091045d87",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note we can also get this from the prompt hub, as noted above\n",
    "reduce_prompt = hub.pull(\"rlm/map-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1da97-d590-4a96-82b2-8002d27fd7f6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.948720Z",
     "iopub.status.idle": "2024-06-14T15:28:35.949056Z",
     "shell.execute_reply": "2024-06-14T15:28:35.948900Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.948884Z"
    },
    "id": "c9d1da97-d590-4a96-82b2-8002d27fd7f6",
    "outputId": "907adf33-fd89-4064-e80f-8acaa1d907c3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduce_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb1b0d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.952647Z",
     "iopub.status.idle": "2024-06-14T15:28:35.953185Z",
     "shell.execute_reply": "2024-06-14T15:28:35.953016Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.952996Z"
    },
    "id": "1edb1b0d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run chain\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# Берет список документов, объединяет их в одну строку и передает в LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    ")\n",
    "\n",
    "# Объединяет и итеративно сокращает сопоставленные документы\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # Это конечная цепочка, которая вызывается.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # Если размер документов выходит за рамки контекста для `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # Максимальное количество токенов для группировки документов.\n",
    "    token_max=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5ae1a",
   "metadata": {
    "id": "fdb5ae1a"
   },
   "source": [
    "Объединяет нашу map and reduce цепочку в одну:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1cdc2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.954324Z",
     "iopub.status.idle": "2024-06-14T15:28:35.954849Z",
     "shell.execute_reply": "2024-06-14T15:28:35.954672Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.954638Z"
    },
    "id": "22f1cdc2",
    "outputId": "0945c0ce-3f1b-4b7b-ba2f-2bc045c9dae3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Объединение документов путем сопоставления цепочки над ними, а затем объединение результатов\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # Имя переменной в llm_chain в которую помещаются документы\n",
    "    document_variable_name=\"docs\",\n",
    "    # Возвращает результаты выполнения шагов сопоставления в выходных данных\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 0\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE, \n",
    "    chunk_overlap=CHUNK_OVERLAP)\n",
    "# text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     chunk_size=1000, chunk_overlap=0\n",
    "# )\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afb8c3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.955661Z",
     "iopub.status.idle": "2024-06-14T15:28:35.956086Z",
     "shell.execute_reply": "2024-06-14T15:28:35.955911Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.955893Z"
    },
    "id": "c7afb8c3",
    "outputId": "9a9f383d-a12a-4136-d821-4801c98ce222",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(map_reduce_chain.run(split_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c21cf",
   "metadata": {
    "id": "e62c21cf"
   },
   "source": [
    "### Дополнительная информация\n",
    "\n",
    "**Что можно \"подкрутить\"**\n",
    "\n",
    "* Как показано выше, вы можете настроить LLM и промпты для этапов map and reduce.\n",
    "\n",
    "**Реальный сценарий**\n",
    "\n",
    "* См. [этот блог-пост](https://blog.langchain.dev/llms-to-improve-documentation/) тематическое исследование по анализу взаимодействий с пользователями (вопросы по LangChain документации)\n",
    "  \n",
    "* Связанный с этим [репозиторий](https://github.com/mendableai/QA_clustering) также представляет кластеризацию как средство для суммаризации (краткого перессказа).\n",
    "* Это открывает третий путь помимо `stuff` или `map-reduce` подходов, который имеет смысл рассматривать\n",
    "\n",
    "![описание схемы](https://github.com/langchain-ai/langchain/blob/master/docs/static/img/summarization_use_case_3.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ff365",
   "metadata": {
    "id": "f08ff365"
   },
   "source": [
    "## Вариант 3. Refine\n",
    "\n",
    "[RefineDocumentsChain](https://python.langchain.com/docs/modules/chains#legacy-chains) похож на map-reduce:\n",
    "\n",
    "> The refine documents создает ответ, перебирая входные документы и итеративно обновляя свой ответ. Для каждого документа он передает все входные данные, не относящиеся к документу, текущий документ и последний промежуточный ответ в цепочку LLM, чтобы получить новый ответ.\n",
    "\n",
    "Это можно легко запустить с помощью `chain_type=\"refine\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1dc10e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.957406Z",
     "iopub.status.idle": "2024-06-14T15:28:35.957913Z",
     "shell.execute_reply": "2024-06-14T15:28:35.957734Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.957701Z"
    },
    "id": "de1dc10e",
    "outputId": "946b074a-08ae-40ef-f06a-826361fe30e8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "print(chain.run(split_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46f44d",
   "metadata": {
    "id": "5b46f44d"
   },
   "source": [
    "Также возможно ввести запрос и вернуть промежуточные шаги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c8072",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.959189Z",
     "iopub.status.idle": "2024-06-14T15:28:35.959730Z",
     "shell.execute_reply": "2024-06-14T15:28:35.959547Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.959524Z"
    },
    "id": "f86c8072",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Напишите краткое изложение следующего:\n",
    "{text}\n",
    "КРАТКОЕ ИЗЛОЖЕНИЕ:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"Твоя задача подготовить окончательное краткое содержание\\n\"\n",
    "    \"Мы предоставили существующую краткую сводку до определенного момента: {existing_answer}\\n\"\n",
    "    \"У нас есть возможность доработать существующую краткую сводку\"\n",
    "    \"(только если требуется) с еще некоторым контекстом ниже.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Учитывая новый контекст, доработайте первоначальную краткую сводку на русском языке\"\n",
    "    \"Если контекст бесполезен, верните исходную краткую сводку.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"input_documents\",\n",
    "    output_key=\"output_text\",\n",
    ")\n",
    "result = chain({\"input_documents\": split_docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9600b67-79d4-4f85-aba2-9fe81fa29f49",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.960787Z",
     "iopub.status.idle": "2024-06-14T15:28:35.961338Z",
     "shell.execute_reply": "2024-06-14T15:28:35.961130Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.961088Z"
    },
    "id": "d9600b67-79d4-4f85-aba2-9fe81fa29f49",
    "outputId": "571e0f5c-c964-4321-daf2-a116a5fb21ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f91a8eb-daa5-4191-ace4-01765801db3e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:35.962295Z",
     "iopub.status.idle": "2024-06-14T15:28:35.963371Z",
     "shell.execute_reply": "2024-06-14T15:28:35.963174Z",
     "shell.execute_reply.started": "2024-06-14T15:28:35.963148Z"
    },
    "id": "5f91a8eb-daa5-4191-ace4-01765801db3e",
    "outputId": "4aaf18c0-e6b6-4726-881d-69b52bd21f20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(result[\"intermediate_steps\"][:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a8398-a43c-4f14-933c-c0743ae6ec40",
   "metadata": {
    "id": "0d8a8398-a43c-4f14-933c-c0743ae6ec40"
   },
   "source": [
    "## Разбивка и суммирование в единую цепочку\n",
    "Для удобства мы можем объединить как разбиение текста нашего длинного документа, так и подведение итогов в одном документе.`AnalyzeDocumentsChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddd522e-30dc-4f6a-b993-c4f97e656c4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T15:28:36.303377Z",
     "iopub.status.busy": "2024-06-14T15:28:36.302168Z",
     "iopub.status.idle": "2024-06-14T15:28:39.192497Z",
     "shell.execute_reply": "2024-06-14T15:28:39.191430Z",
     "shell.execute_reply.started": "2024-06-14T15:28:36.303336Z"
    },
    "id": "0ddd522e-30dc-4f6a-b993-c4f97e656c4f",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1968/570070396.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m summarize_document_chain = AnalyzeDocumentChain(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcombine_docs_chain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_splitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_splitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummarize_document_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chain' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.chains import AnalyzeDocumentChain\n",
    "\n",
    "summarize_document_chain = AnalyzeDocumentChain(\n",
    "    combine_docs_chain=chain, text_splitter=text_splitter\n",
    ")\n",
    "summary=summarize_document_chain.invoke(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df14d0-d548-4a5d-b00a-f4cfd64f1076",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:39.193139Z",
     "iopub.status.idle": "2024-06-14T15:28:39.193538Z",
     "shell.execute_reply": "2024-06-14T15:28:39.193384Z",
     "shell.execute_reply.started": "2024-06-14T15:28:39.193365Z"
    },
    "id": "d8df14d0-d548-4a5d-b00a-f4cfd64f1076",
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae35712f-49ad-44e3-bfc9-4582ea684e0b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-14T15:28:39.194168Z",
     "iopub.status.idle": "2024-06-14T15:28:39.194553Z",
     "shell.execute_reply": "2024-06-14T15:28:39.194386Z",
     "shell.execute_reply.started": "2024-06-14T15:28:39.194368Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(summary.get('input_document'))\n",
    "print(summary.get('intermediate_steps'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60010c-7d1c-4513-9c18-f408c2f70f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448adb2-3267-473b-8f9d-65e2ec017280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
